<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="今天科研了吗">
<meta property="og:type" content="website">
<meta property="og:title" content="枫叶苑">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="枫叶苑">
<meta property="og:description" content="今天科研了吗">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="枫叶">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>枫叶苑</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">枫叶苑</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="download fa-fw"></i>资源</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/08/MachineLearningAndrew/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="枫叶">
      <meta itemprop="description" content="今天科研了吗">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶苑">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/08/MachineLearningAndrew/" class="post-title-link" itemprop="url">Machine Learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-10-08 17:01:13" itemprop="dateCreated datePublished" datetime="2023-10-08T17:01:13+08:00">2023-10-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-15 00:14:03" itemprop="dateModified" datetime="2023-10-15T00:14:03+08:00">2023-10-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Class-1-有监督机器学习回归和分类"><a href="#Class-1-有监督机器学习回归和分类" class="headerlink" title="Class 1 有监督机器学习回归和分类"></a>Class 1 有监督机器学习回归和分类</h1><h2 id="Week3-逻辑回归"><a href="#Week3-逻辑回归" class="headerlink" title="Week3 逻辑回归"></a>Week3 逻辑回归</h2><h3 id="二元分类"><a href="#二元分类" class="headerlink" title="二元分类"></a>二元分类</h3><p>这种只有两种可能输出的分类问题称为二元分类。</p>
<h3 id="sigmoid-函数"><a href="#sigmoid-函数" class="headerlink" title="sigmoid 函数"></a>sigmoid 函数</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231008173829773.png" alt="image-20231008173829773"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008173915794.png" alt="image-20231008173915794"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008174151181.png" alt="image-20231008174151181">             <img src="/2023/10/08/MachineLearningAndrew/image-20231008174227410.png" alt="image-20231008174227410"></p>
<p>输入特征，输出0到1</p>
<h3 id="决策边界"><a href="#决策边界" class="headerlink" title="决策边界"></a>决策边界</h3><p>线性or非线性</p>
<h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>平方误差成本函数不是逻辑回归的理想成本函数。</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008205513401.png" alt="image-20231008205513401"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008205613800.png" alt="image-20231008205613800"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008205638121.png" alt="image-20231008205638121"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008205807667.png" alt="image-20231008205807667"></p>
<p>请记住，损失函数衡量的是你在一个训练样例上的表现如何，它是通过总结你随后获得的所有训练样例的损失，成本函数衡量你在整个训练集上的表现。</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008210426343.png" alt="image-20231008210426343"></p>
<p>整体成本函数为凸函数，可以获得全局最小值</p>
<p>简化损失函数</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008211105952.png" alt="image-20231008211105952"></p>
<p>代价函数</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008211415275.png" alt="image-20231008211415275"></p>
<p>使用最大似然估计推导出来，是凸函数</p>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231008211755913.png" alt="image-20231008211755913"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008211932119.png" alt="image-20231008211932119"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008211950319.png" alt="image-20231008211950319"></p>
<p>Same concepts:</p>
<ul>
<li>Monitor gradient descent(learning curve)</li>
<li>Vectorized implementation</li>
<li>Feature scaling</li>
</ul>
<h3 id="过拟合与欠拟合"><a href="#过拟合与欠拟合" class="headerlink" title="过拟合与欠拟合"></a>过拟合与欠拟合</h3><p>欠拟合：高偏差 high bias  Does not fit thetraining set well</p>
<p>过拟合：高方差 high variance Fits the training setextremely well</p>
<h3 id="解决过拟合"><a href="#解决过拟合" class="headerlink" title="解决过拟合"></a>解决过拟合</h3><p>收集更多的训练样本</p>
<p>选择特征   select features to include&#x2F;exclude</p>
<p>正则化 Regularization 正则化是一种更温和地减少某些特征影响的方法，而不用像彻底消除它那样严厉。</p>
<p>那么正则化的作用是，它可以让你保留所有特征，但它们只是防止特征产生过大的影响，而这有时会导致过度拟合。</p>
<h3 id="正则化-Regularization"><a href="#正则化-Regularization" class="headerlink" title="正则化 Regularization"></a>正则化 Regularization</h3><p>λ正则化参数</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008223908932.png" alt="image-20231008223908932"></p>
<p>正则化线性回归</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008224030737.png" alt="image-20231008224030737"></p>
<p>梯度下降</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231008224109310.png" alt="image-20231008224109310"></p>
<p>正则化逻辑回归</p>
<h1 id><a href="#" class="headerlink" title></a><img src="/2023/10/08/MachineLearningAndrew/image-20231008225551317.png" alt="image-20231008225551317"></h1><h1 id="Class-3-深度学习"><a href="#Class-3-深度学习" class="headerlink" title="Class 3 深度学习"></a>Class 3 深度学习</h1><h2 id="Week1-神经网络"><a href="#Week1-神经网络" class="headerlink" title="Week1 神经网络"></a>Week1 神经网络</h2><p>输入层 输入为特征向量</p>
<p>隐藏层</p>
<p>输出层</p>
<p><strong>Tensorflow and Keras</strong><br>Tensorflow is a machine learning package developed by Google. In 2019, Google integrated Keras into Tensorflow and released Tensorflow 2.0. Keras is a framework developed independently by François Chollet that creates a simple, layer-centric interface to Tensorflow. This course will be using the Keras interface. </p>
<p>激活函数g(x)是sigmoid函数</p>
<p>前向传播算法</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231009222124079.png" alt="image-20231009222124079"></p>
<p>从左到右向前计算，称为前向传播</p>
<p>离输出层越近，隐藏层神经元越少</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231009222647437.png" alt="image-20231009222647437"></p>
<p>两个特征，第一个隐藏层有三个神经元，激活函数为sigmoid，输出为a1，第二层同理</p>
<p>输入向量要写成二维矩阵形式 x &#x3D; np.array([[200,17]])  1x2矩阵</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231009224920509.png" alt="image-20231009224920509"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231009224946845.png" alt="image-20231009224946845"></p>
<p>AGI 通用人工智能</p>
<h2 id="Week2-Tenserflow实现"><a href="#Week2-Tenserflow实现" class="headerlink" title="Week2 Tenserflow实现"></a>Week2 Tenserflow实现</h2><p><img src="/2023/10/08/MachineLearningAndrew/image-20231010125603129.png" alt="image-20231010125603129"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010125701208.png" alt="image-20231010125701208"></p>
<p>交叉熵损失函数</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010130715345.png" alt="image-20231010130715345"></p>
<p>回归和分类使用不同的损失代价函数</p>
<p>梯度下降</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010130841602.png" alt="image-20231010130841602"></p>
<p>多层感知器：多层神经网路</p>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><h4 id="ReLU-Activation"><a href="#ReLU-Activation" class="headerlink" title="ReLU Activation"></a>ReLU Activation</h4><p>This week, a new activation was introduced, the Rectified Linear Unit (ReLU).</p>
<p>𝑎&#x3D;𝑚𝑎𝑥(0,𝑧)# ReLU function<img src="/2023/10/08/MachineLearningAndrew/image-20231010204558837.png" alt="image-20231010204558837"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010204715345.png" alt="image-20231010204715345"></p>
<p>二分类问题，sigmoid激活函数是最自然的选择，输出层使用</p>
<p>回归模型，输出有正有负，预测明天的股票价格，输出层使用线性激活函数</p>
<p>回归模型，输出为非负，预测房屋价格，非负，输出层选择ReLU函数</p>
<p>隐藏层选择Relu函数，ReLU计算速度更快，效率高，但事实证明更重要的第二个原因是ReLU函数仅在图形的一部分变平;左边这里<br>是完全平坦的，而sigmoid激活函数，它在两个地方变得平坦。梯度下降就会很慢，减慢学习速度</p>
<p>为什么要使用激活函数？</p>
<p>若所有层都是用线性激活函数，那就变成了线性回归</p>
<h3 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h3><h3 id="Softmax函数"><a href="#Softmax函数" class="headerlink" title="Softmax函数"></a>Softmax函数</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231010212144511.png" alt="image-20231010212144511"></p>
<h4 id="代价函数-1"><a href="#代价函数-1" class="headerlink" title="代价函数"></a>代价函数</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231010212557352.png" alt="image-20231010212557352"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010220105018.png" alt="image-20231010220105018"></p>
<h4 id="Tenserflow-实现"><a href="#Tenserflow-实现" class="headerlink" title="Tenserflow 实现"></a>Tenserflow 实现</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231010220327241.png" alt="image-20231010220327241"></p>
<h4 id="改进实现"><a href="#改进实现" class="headerlink" title="改进实现"></a>改进实现</h4><p>避免计算过程中出现过大或者过小值造成计算错误，改进方法在计算过程中进行了重新排列</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010221115720.png" alt="image-20231010221115720"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010221418604.png" alt="image-20231010221418604"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010221520301.png" alt="image-20231010221520301"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010221537117.png" alt="image-20231010221537117"></p>
<h3 id="多标签分类"><a href="#多标签分类" class="headerlink" title="多标签分类"></a>多标签分类</h3><p>一个神经网络同时检测多个目标</p>
<h3 id="更快的训练方法"><a href="#更快的训练方法" class="headerlink" title="更快的训练方法"></a>更快的训练方法</h3><h4 id="Adam算法"><a href="#Adam算法" class="headerlink" title="Adam算法"></a>Adam算法</h4><p>自动调节α</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010231015869.png" alt="image-20231010231015869"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010231157191.png" alt="image-20231010231157191"></p>
<h3 id="其他的网络层"><a href="#其他的网络层" class="headerlink" title="其他的网络层"></a>其他的网络层</h3><p>密集层</p>
<p>卷积层</p>
<ul>
<li><p>更快的计算</p>
</li>
<li><p>需要更少的训练数据，不太会过拟合</p>
</li>
</ul>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231010231710233.png" alt="image-20231010231710233"></p>
<h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231010235541548.png" alt="image-20231010235541548"></p>
<h2 id="Week3-在机器学习项目中下一步该做什么"><a href="#Week3-在机器学习项目中下一步该做什么" class="headerlink" title="Week3 在机器学习项目中下一步该做什么"></a>Week3 在机器学习项目中下一步该做什么</h2><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011083027133.png" alt="image-20231011083027133"></p>
<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><p>训练集分为两个子集</p>
<p>training set</p>
<p>test set</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011083802084.png" alt="image-20231011083802084"></p>
<p>不包含正则化项</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011084012544.png" alt="image-20231011084012544"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011084442975.png" alt="image-20231011084442975"></p>
<p>就是相比于之前计算在测试集和训练集上误差的那两个公式，我们更常用模型分类错误的次数除以总的预测次数来表示误差</p>
<p>就是对于逻辑回归来说，可以通过计算误判占比的方法来代表成本函数，比如test set中误判的占比是10％，那么J test就是0.1</p>
<h4 id="分为三个子集，训练集、交叉验证集、测试集"><a href="#分为三个子集，训练集、交叉验证集、测试集" class="headerlink" title="分为三个子集，训练集、交叉验证集、测试集"></a>分为三个子集，训练集、交叉验证集、测试集</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011091646019.png" alt="image-20231011091646019"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011091757791.png" alt="image-20231011091757791"></p>
<p>选择最小的交叉验证集误差对应的模型</p>
<p>用测试集来评估泛化误差</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011092256493.png" alt="image-20231011092256493"></p>
<h4 id="偏差和方差"><a href="#偏差和方差" class="headerlink" title="偏差和方差"></a>偏差和方差</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011093159868.png" alt="image-20231011093159868"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011093401564.png" alt="image-20231011093401564"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011093433520.png" alt="image-20231011093433520"></p>
<p>正则化如何影响偏差和方差，从而影响算法的性能</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011093859951.png" alt="image-20231011093859951"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011094124259.png" alt="image-20231011094124259"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011094256539.png" alt="image-20231011094256539"></p>
<h4 id="指定一个用于性能评估的基准"><a href="#指定一个用于性能评估的基准" class="headerlink" title="指定一个用于性能评估的基准"></a>指定一个用于性能评估的基准</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011103735186.png" alt="image-20231011103735186"></p>
<p>竞争算法</p>
<h4 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011104512509.png" alt="image-20231011104512509"></p>
<p>训练集变大，误差增大</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011104852894.png" alt="image-20231011104852894"></p>
<p>这给出了这个结论，也许有点令人惊讶，如果学习算法具有高偏差，获得更多的训<br>练数据本身就没有那么大的希望。</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011105426342.png" alt="image-20231011105426342"></p>
<p>所以在这种情况下，可能仅仅通过增加训练集的大小来降低交叉验证误差并让你的算法表现得越来越好，这与高偏差情况不同，在这种情况下你唯一要做的就是获得更多的训练数据，实际上并不能帮助您了解算法性能。</p>
<h4 id="如何改进"><a href="#如何改进" class="headerlink" title="如何改进"></a>如何改进</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011110222504.png" alt="image-20231011110222504"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011110708303.png" alt="image-20231011110708303"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011111707005.png" alt="image-20231011111707005"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011112028987.png" alt="image-20231011112028987"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011112250065.png" alt="image-20231011112250065"></p>
<h3 id="机器学习开发的迭代"><a href="#机器学习开发的迭代" class="headerlink" title="机器学习开发的迭代"></a>机器学习开发的迭代</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011112605831.png" alt="image-20231011112605831"></p>
<p>垃圾邮件分类</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011112929003.png" alt="image-20231011112929003"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011113910756.png" alt="image-20231011113910756"></p>
<h4 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011114442995.png" alt="image-20231011114442995"></p>
<h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><p>旋转图像扭曲放大缩小</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011115040740.png" alt="image-20231011115040740"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011115116926.png" alt="image-20231011115116926"></p>
<p>音频增强 </p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011115211067.png" alt="image-20231011115211067"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011115324412.png" alt="image-20231011115324412"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011131113956.png" alt="image-20231011131113956"></p>
<h4 id="迁移学习-Transfer-learning"><a href="#迁移学习-Transfer-learning" class="headerlink" title="迁移学习 Transfer  learning"></a>迁移学习 Transfer  learning</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011163140324.png" alt="image-20231011163140324"></p>
<p>数据集小选择1，数据集大选择二</p>
<p>先在大的数据集训练（监督与训练），再在小的训练称为微调</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011163230072.png" alt="image-20231011163230072"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011163351440.png" alt="image-20231011163351440"></p>
<h4 id="机器学习项目全周期"><a href="#机器学习项目全周期" class="headerlink" title="机器学习项目全周期"></a>机器学习项目全周期</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231011163931188.png" alt="image-20231011163931188"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011164414049.png" alt="image-20231011164414049"></p>
<h4 id="倾斜数据集的误差指标"><a href="#倾斜数据集的误差指标" class="headerlink" title="倾斜数据集的误差指标"></a>倾斜数据集的误差指标</h4><p>精确度和召回率</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011165618174.png" alt="image-20231011165618174"></p>
<p>精度和召回率</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011170439331.png" alt="image-20231011170439331"></p>
<p>F1score 更强调P和R中较低的那个 调和平均值</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231011170740787.png" alt="image-20231011170740787"></p>
<h2 id="Week4-决策树"><a href="#Week4-决策树" class="headerlink" title="Week4 决策树"></a>Week4 决策树</h2><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012075401986.png" alt="image-20231012075401986"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012075410387.png" alt="image-20231012075410387"></p>
<p>根节点 决策节点 叶节点</p>
<p>决策树学习算法的工作是，从所有可能的决策树中，尝试选择一个希望在训练集上<br>表现良好的树，然后理想地泛化到新数据，例如交叉验证和测试集</p>
<h3 id="学习过程"><a href="#学习过程" class="headerlink" title="学习过程"></a>学习过程</h3><p>决策树学习的第一步是，我们必须决定在根节点使用什么特征。</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012081611286.png" alt="image-20231012081611286"></p>
<p>Decision 2: When do you stop splitting?</p>
<ul>
<li>When a node is 100% one class</li>
<li>When splitting a node will result in the tree exceeding a maximum depth</li>
<li>When improvements in purity score are below a threshold</li>
<li>When number of examples in a node is below a threshold</li>
</ul>
<p>您可能想要限制决策树深度的一个原因是确保我们的树不会变得太大和笨重，其<br>次，通过保持树小，它不太容易过度拟合。</p>
<h3 id="纯度"><a href="#纯度" class="headerlink" title="纯度"></a>纯度</h3><h4 id="熵-entropy"><a href="#熵-entropy" class="headerlink" title="熵 entropy"></a>熵 entropy</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012082638836.png" alt="image-20231012082638836"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012082823450.png" alt="image-20231012082823450"></p>
<p>选择拆分信息增益</p>
<p>减少熵</p>
<p>信息增益 分之前的熵减去分后熵的加权平均</p>
<p>停止标准，每次信息增益如果太小停止分类</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012083632353.png" alt="image-20231012083632353"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012083921344.png" alt="image-20231012083921344"></p>
<h4 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h4><ul>
<li>Start with all examples at the root node</li>
<li>Calculate information gain for all possible features, and pick the one with the highest information gain</li>
<li>Split dataset according to selected feature,and create left and right branches of the tree</li>
<li>Keep repeating splitting process until stopping criteria is met:<ul>
<li>when a node is 100% one class</li>
<li>When splitting a node will result in the tree exceeding a maximum depth</li>
<li>Information gain from additional splits is less than threshold</li>
<li>When number of examples in a node is below a threshold</li>
</ul>
</li>
</ul>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012084601880.png" alt="image-20231012084601880"></p>
<p>递归分类</p>
<h3 id="独热编码-one-hot"><a href="#独热编码-one-hot" class="headerlink" title="独热编码 one-hot"></a>独热编码 one-hot</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012085239987.png" alt="image-20231012085239987"></p>
<p>通过one-hot编码，您可以让决策树处理可以采用两个以上离散值的特征，您还可以将其应用于新网络或线性回归或逻辑回归训练。</p>
<p>连续值</p>
<p>尝试不同的阈值，计算纯度</p>
<h3 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012090404205.png" alt="image-20231012090404205"></p>
<p>尝试减少方差</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012091154958.png" alt="image-20231012091154958"></p>
<h3 id="使用多个决策树"><a href="#使用多个决策树" class="headerlink" title="使用多个决策树"></a>使用多个决策树</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012092643280.png" alt="image-20231012092643280"></p>
<h4 id="有放回的采样"><a href="#有放回的采样" class="headerlink" title="有放回的采样"></a>有放回的采样</h4><p>构建新的数据集，</p>
<p>Random Forest Algorithm</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012093230276.png" alt="image-20231012093230276"></p>
<p>Randomizing the feature choice<br>At each node, when choosing a feature to use to split,if n features are available, pick a random subset of k &lt;n features and allow the algorithm to only choose from that subset of features.</p>
<p>k的选择（根号n，log2(n)）</p>
<h4 id="XGBoost-extreme-Gradient-Boosting"><a href="#XGBoost-extreme-Gradient-Boosting" class="headerlink" title="XGBoost (extreme Gradient Boosting)"></a>XGBoost (extreme Gradient Boosting)</h4><p>内置正则化防止过度拟合</p>
<ul>
<li>Open source implementation of boosted trees</li>
<li>Fast efficient implementation</li>
<li>Good choice of default splitting criteria and criteria for when to stop splitting</li>
<li>Built in regularization to prevent over fitting</li>
<li>Highly competitive algorithm for machine learning competitions (eg: Kaggle competitions)</li>
</ul>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012094738491.png" alt="image-20231012094738491"></p>
<h3 id="何时使用决策树"><a href="#何时使用决策树" class="headerlink" title="何时使用决策树"></a>何时使用决策树</h3><p>表格数据</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012095356821.png" alt="image-20231012095356821"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012095814528.png" alt="image-20231012095814528"></p>
<h1 id="Class3-无监督学习"><a href="#Class3-无监督学习" class="headerlink" title="Class3 无监督学习"></a>Class3 无监督学习</h1><h2 id="Week1-无监督学习"><a href="#Week1-无监督学习" class="headerlink" title="Week1 无监督学习"></a>Week1 无监督学习</h2><h3 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h3><h4 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012125528206.png" alt="image-20231012125528206"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012125536447.png" alt="image-20231012125536447"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012130426099.png" alt="image-20231012130426099"></p>
<p>如果一个集群训练样本为零，可以消除该集群，最终得到k-1；另一种方法是重新初始化该集群质心</p>
<h4 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012145049473.png" alt="image-20231012145049473"></p>
<h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012150757199.png" alt="image-20231012150757199"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012151542672.png" alt="image-20231012151542672"></p>
<h4 id="选择聚类数量"><a href="#选择聚类数量" class="headerlink" title="选择聚类数量"></a>选择聚类数量</h4><p>肘法</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012151925053.png" alt="image-20231012151925053"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012152146445.png" alt="image-20231012152146445"></p>
<h3 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012152706177.png" alt="image-20231012152706177"></p>
<h4 id="密度估计"><a href="#密度估计" class="headerlink" title="密度估计"></a>密度估计</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012152845235.png" alt="image-20231012152845235"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012153346742.png" alt="image-20231012153346742"></p>
<h4 id="高斯正态分布"><a href="#高斯正态分布" class="headerlink" title="高斯正态分布"></a>高斯正态分布</h4><p>最大似然估计</p>
<h4 id="异常检测算法"><a href="#异常检测算法" class="headerlink" title="异常检测算法"></a>异常检测算法</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012154133115.png" alt="image-20231012154133115"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012154923207.png" alt="image-20231012154923207"></p>
<h4 id="开发与评估异常检测系统"><a href="#开发与评估异常检测系统" class="headerlink" title="开发与评估异常检测系统."></a>开发与评估异常检测系统.</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231012215712447.png" alt="image-20231012215712447"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231012220215931.png" alt="image-20231012220215931"></p>
<p>这种替代方案的缺点是，在调整算法后，您没有公平的方法来判断它在未来示例中的实际效果如何，因为您没有测试集。</p>
<p>当你的数据集很小的时候，特别是当你有异常的数量时，你的数据集很小，这可能是你最好的选择。</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013082659472.png" alt="image-20231013082659472"></p>
<h4 id="异常检测vs监督学习"><a href="#异常检测vs监督学习" class="headerlink" title="异常检测vs监督学习"></a>异常检测vs监督学习</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013084827450.png" alt="image-20231013084827450"></p>
<p>例子</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013084924028.png" alt="image-20231013084924028"></p>
<h4 id="选择用什么特征"><a href="#选择用什么特征" class="headerlink" title="选择用什么特征"></a>选择用什么特征</h4><p>特征改变为高斯分布</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013085546244.png" alt="image-20231013085546244"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013090207839.png" alt="image-20231013090207839"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013090413780.png" alt="image-20231013090413780"></p>
<h2 id="Week2-推荐系统"><a href="#Week2-推荐系统" class="headerlink" title="Week2 推荐系统"></a>Week2 推荐系统</h2><h3 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h3><h4 id="使用每个特征数据"><a href="#使用每个特征数据" class="headerlink" title="使用每个特征数据"></a>使用每个特征数据</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013091417801.png" alt="image-20231013091417801"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013092525171.png" alt="image-20231013092525171"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013092709205.png" alt="image-20231013092709205"></p>
<h4 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h4><p>假设已经有了w和b，猜测特征x</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013093541589.png" alt="image-20231013093541589"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013094256436.png" alt="image-20231013094256436"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013094536963.png" alt="image-20231013094536963"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013095022269.png" alt="image-20231013095022269"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013095116749.png" alt="image-20231013095116749"></p>
<p>这种协同过滤是从多个用户收集数据，用户之间的这种协作可帮助您预测未来甚至其他用户的评级。</p>
<p>推荐系统的一个非常常见的用例是当您有二进制标签时，例如用户喜欢、喜欢或与项目交互的标签。</p>
<h4 id="二进制标签"><a href="#二进制标签" class="headerlink" title="二进制标签"></a>二进制标签</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013095506383.png" alt="image-20231013095506383"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013095650568.png" alt="image-20231013095650568"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013095901608.png" alt="image-20231013095901608"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013100113430.png" alt="image-20231013100113430"></p>
<p>分类不用正则化</p>
<h4 id="均值归一化"><a href="#均值归一化" class="headerlink" title="均值归一化"></a>均值归一化</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013143727458.png" alt="image-20231013143727458"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013144130791.png" alt="image-20231013144130791"></p>
<p>对未知用户，预测评分为均值</p>
<h4 id="协同过滤Tensorflow实现"><a href="#协同过滤Tensorflow实现" class="headerlink" title="协同过滤Tensorflow实现"></a>协同过滤Tensorflow实现</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013144725579.png" alt="image-20231013144725579"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013144803015.png" alt="image-20231013144803015"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013145539351.png" alt="image-20231013145539351"></p>
<h4 id="寻找相关特征"><a href="#寻找相关特征" class="headerlink" title="寻找相关特征"></a>寻找相关特征</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013145951931.png" alt="image-20231013145951931"></p>
<p>协同过滤的局限性</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013150021292.png" alt="image-20231013150021292"></p>
<p>冷启动问题</p>
<p>边缘信息</p>
<h4 id="基于内容的过滤算法"><a href="#基于内容的过滤算法" class="headerlink" title="基于内容的过滤算法"></a>基于内容的过滤算法</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013150639264.png" alt="image-20231013150639264"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013150936617.png" alt="image-20231013150936617"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013151110932.png" alt="image-20231013151110932"></p>
<p>如何计算V</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013151407807.png" alt="image-20231013151407807"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013151905392.png" alt="image-20231013151905392"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013152534237.png" alt="image-20231013152534237"></p>
<h4 id="从大型目录中推荐"><a href="#从大型目录中推荐" class="headerlink" title="从大型目录中推荐"></a>从大型目录中推荐</h4><p>两个步骤：检索和排名</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013152823434.png" alt="image-20231013152823434"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013153036731.png" alt="image-20231013153036731"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013153343967.png" alt="image-20231013153343967"></p>
<h4 id="基于内容的Tensorflow实现"><a href="#基于内容的Tensorflow实现" class="headerlink" title="基于内容的Tensorflow实现"></a>基于内容的Tensorflow实现</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013154612258.png" alt="image-20231013154612258"></p>
<h4 id="降低特征数量"><a href="#降低特征数量" class="headerlink" title="降低特征数量"></a>降低特征数量</h4><p>PCA主成分分析法，特征降为二维或者三维，便于可视化</p>
<h4 id="PCA算法"><a href="#PCA算法" class="headerlink" title="PCA算法"></a>PCA算法</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013170727751.png" alt="image-20231013170727751"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013171217861.png" alt="image-20231013171217861"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013171447596.png" alt="image-20231013171447596"></p>
<p>当使用线性回归来预测目标输出Y并且PCA试图获取大量特征并平等对待它们并减少很好地表示数据所需的轴数</p>
<p>因此，如果您尝试预测y的值，则应使用线性回归;如果您尝试减少数据集中的特征数量，例如将其可视化，则应使用PCA。</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013172253829.png" alt="image-20231013172253829"></p>
<p>每个特征的方差贡献率</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013172530272.png" alt="image-20231013172530272"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013172923497.png" alt="image-20231013172923497"></p>
<h2 id="Week3-强化学习"><a href="#Week3-强化学习" class="headerlink" title="Week3 强化学习"></a>Week3 强化学习</h2><h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013185527334.png" alt="image-20231013185527334"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013185513926.png" alt="image-20231013185513926"></p>
<p>状态、动作、奖励和下一个状态（s，a，R（s），s‘)</p>
<h4 id="回报"><a href="#回报" class="headerlink" title="回报"></a>回报</h4><p>折扣因子</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013191147456.png" alt="image-20231013191147456"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013191515723.png" alt="image-20231013191515723"></p>
<h4 id="决策"><a href="#决策" class="headerlink" title="决策"></a>决策</h4><p>pi</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013191936751.png" alt="image-20231013191936751"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013192130503.png" alt="image-20231013192130503"></p>
<p>马尔可夫决策过程</p>
<p>在马尔可夫决策过程中，未来只取决于你现在所处的位置，而不取决于你是如何到达这里的。</p>
<h4 id="状态-动作价值函数"><a href="#状态-动作价值函数" class="headerlink" title="状态-动作价值函数"></a>状态-动作价值函数</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013214059896.png" alt="image-20231013214059896"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013214515098.png" alt="image-20231013214515098"></p>
<h4 id="贝尔曼方程"><a href="#贝尔曼方程" class="headerlink" title="贝尔曼方程"></a>贝尔曼方程</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013220256063.png" alt="image-20231013220256063"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013221245911.png" alt="image-20231013221245911"></p>
<p>如果你从状态s 开始，你将采取行动a，然后在此之后采取最佳行动，那么你将随着时间的推移看到一些奖励序列。</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013221652384.png" alt="image-20231013221652384"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013221916868.png" alt="image-20231013221916868"></p>
<h4 id="随机强化学习"><a href="#随机强化学习" class="headerlink" title="随机强化学习"></a>随机强化学习</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013222607911.png" alt="image-20231013222607911"></p>
<h4 id="连续状态"><a href="#连续状态" class="headerlink" title="连续状态"></a>连续状态</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013222846102.png" alt="image-20231013222846102"></p>
<p>连续马尔可夫 MTP</p>
<h4 id="学习状态值函数"><a href="#学习状态值函数" class="headerlink" title="学习状态值函数"></a>学习状态值函数</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013223922575.png" alt="image-20231013223922575"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013224639866.png" alt="image-20231013224639866"></p>
<p>不知道Q，随机猜测</p>
<h4 id="DQN-p146"><a href="#DQN-p146" class="headerlink" title="DQN  p146"></a>DQN  p146</h4><p>意思是神经网络里的参数随机初始化，然后(s’,a’)输入，得到maxQ的预测</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013225256166.png" alt="image-20231013225256166"></p>
<p>交给神经网络训练的参数y中一部分是随机初始化神经网络生成的，但还有一部分是包含了当前状态的信息的，所以当训练次数增多后，外部的输入信息会逐步冲刷掉初始化的随机信息，给出真正的Q函数估计</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013225733542.png" alt="image-20231013225733542"></p>
<h4 id="贪婪算法"><a href="#贪婪算法" class="headerlink" title="贪婪算法"></a>贪婪算法</h4><p>使用高ε开始，逐步降低直到0.01</p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013230506858.png" alt="image-20231013230506858"></p>
<h4 id="小批量和软更新"><a href="#小批量和软更新" class="headerlink" title="小批量和软更新"></a>小批量和软更新</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013230853479.png" alt="image-20231013230853479"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013231149426.png" alt="image-20231013231149426"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013231255361.png" alt="image-20231013231255361"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231013231653864.png" alt="image-20231013231653864"></p>
<h4 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h4><p><img src="/2023/10/08/MachineLearningAndrew/image-20231013232030585.png" alt="image-20231013232030585"></p>
<p><img src="/2023/10/08/MachineLearningAndrew/image-20231015001350105.png" alt="image-20231015001350105"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/08/DataStruction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="枫叶">
      <meta itemprop="description" content="今天科研了吗">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶苑">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/08/DataStruction/" class="post-title-link" itemprop="url">Data Struction</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-10-08 17:01:11 / 修改时间：23:40:48" itemprop="dateCreated datePublished" datetime="2023-10-08T17:01:11+08:00">2023-10-08</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="线性结构逆转-Reversing-Linked-List"><a href="#线性结构逆转-Reversing-Linked-List" class="headerlink" title="线性结构逆转 Reversing Linked List"></a>线性结构逆转 Reversing Linked List</h1><p>抽象的链表</p>
<ul>
<li>有块地方存数据</li>
<li>有块地方存指针——下一个结点的地址</li>
</ul>
<p>单链表的逆转</p>
<ul>
<li>加一个头节点</li>
</ul>
<img src="/2023/10/08/DataStruction/image-20231008171101380.png" alt="image-20231008171101380" style="zoom:80%;">

<img src="/2023/10/08/DataStruction/image-20231008171509750.png" alt="image-20231008171509750" style="zoom:70%;">

<h1 id="第三讲-树"><a href="#第三讲-树" class="headerlink" title="第三讲 树"></a>第三讲 树</h1><h2 id="3-1-树的定义"><a href="#3-1-树的定义" class="headerlink" title="3.1 树的定义"></a>3.1 树的定义</h2><h3 id="3-1-1-查找"><a href="#3-1-1-查找" class="headerlink" title="3.1.1 查找"></a>3.1.1 查找</h3><p>查找:根据某个给定关键字K,从集合R中找出关键字与K相同的记录</p>
<ul>
<li>静态查找:集合中记录是固定的<ul>
<li>没有插入和删除操作，只有查找</li>
</ul>
</li>
<li>动态查找:集合中记录是动态变化的<ul>
<li>除查找，还可能发生插入和删除</li>
</ul>
</li>
</ul>
<h3 id="3-1-2-静态查找"><a href="#3-1-2-静态查找" class="headerlink" title="3.1.2 静态查找"></a>3.1.2 静态查找</h3><h4 id="顺序查找"><a href="#顺序查找" class="headerlink" title="顺序查找"></a>顺序查找</h4><p>利用哨兵，时间复杂度为O(n)</p>
<p><img src="/2023/10/08/DataStruction/image-20231008194902387.png" alt="image-20231008194902387"></p>
<h4 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h4><p>假设n个数据元素的关键字满足有序（比如:小到大)</p>
<p>并且是连续存放（数组)，那么可以进行二分查找。</p>
<p> <img src="/2023/10/08/DataStruction/image-20231008200450402.png" alt="image-20231008200450402"></p>
<p>二分查找算法具有对数的时间复杂度O(logN)</p>
<p>二分查找判定树</p>
<p><img src="/2023/10/08/DataStruction/image-20231008201408322.png" alt="image-20231008201408322"></p>
<p>判定树上每个结点需要的查找次数刚好为该结点所在的层数;</p>
<p>查找成功时查找次数不会超过判定树的深度</p>
<p>n个结点的判定树的深度为[log_2_n]+1.</p>
<h3 id="3-1-3-树的定义"><a href="#3-1-3-树的定义" class="headerlink" title="3.1.3 树的定义"></a>3.1.3 树的定义</h3><p>树（Tree）：n（n≥0）个结点构成的有限集合</p>
<p>当 n&#x3D;0 时，称为<strong>空树</strong></p>
<h4 id="1-特征"><a href="#1-特征" class="headerlink" title="1.特征"></a>1.特征</h4><p>对于任一棵非空树（n＞0），它具备以下特征：</p>
<ul>
<li>树中有个称为“根（Root）”的特殊结点，用 r 表示</li>
<li>其余结点可分为 m(m&gt;0) 个互不相交的有限集 T<del>1</del> ，T<del>2</del> ,…, T<del>m</del>,其中每个集合本身又是一棵树，称为原来树的”子树（SubTree）”</li>
<li>子树是不相交的</li>
<li>除根结点外，每个结点有且仅有一个父结点</li>
<li>一棵 N 个结点的树有 N-1 条边</li>
</ul>
<h4 id="2-基本术语"><a href="#2-基本术语" class="headerlink" title="2. 基本术语"></a>2. 基本术语</h4><ul>
<li>结点的度（Degree）：结点的子树个数</li>
<li>树的度：树的所有结点中最大的度数</li>
<li>叶结点（Leaf）：度为 0 的结点</li>
<li>父结点（Parent）：有子树的结点是其子树的根结点的父结点</li>
<li>子结点（Child）：若 A 结点是 B 结点的父结点，则称 B 结点是 A 结点的子结点，也称孩子结点</li>
<li>兄弟结点（Sibling）：具有同一父结点的各个结点彼此是兄弟结点</li>
<li>路径：从结点 n<del>1</del> 到n<del>k</del>  的路径为一个结点序列</li>
<li>路径长度：路径所包含边的个数</li>
<li>祖先结点（Ancestor）：沿树根到某一结点路径上的所有结点都是这个结点的祖先结点</li>
<li>子孙结点（Descendant）：某一结点的子树中的所有结点是这个结点的子孙</li>
<li>结点的层次（Level）：规定根结点在 1 层，其他任一结点的层数是其父结点的层数加一</li>
<li>树的深度（Depth）：树中所有结点中的最大层次是这棵树的深度</li>
</ul>
<h4 id="3-树的表示"><a href="#3-树的表示" class="headerlink" title="3. 树的表示"></a>3. 树的表示</h4><p>儿子兄弟表示法</p>
<ul>
<li>Element 存值</li>
<li>FirstChild 指向第一个儿子</li>
<li>NextSibling 指向下一个兄弟</li>
</ul>
<p><img src="/2023/10/08/DataStruction/image-20231008204528987.png" alt="image-20231008204528987"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/08/C++PrimerPlus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="枫叶">
      <meta itemprop="description" content="今天科研了吗">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶苑">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/08/C++PrimerPlus/" class="post-title-link" itemprop="url">C++ Primer Plus</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-10-08 15:27:44 / 修改时间：23:38:31" itemprop="dateCreated datePublished" datetime="2023-10-08T15:27:44+08:00">2023-10-08</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="第八章-函数探幽"><a href="#第八章-函数探幽" class="headerlink" title="第八章 函数探幽"></a>第八章 函数探幽</h1><h2 id="8-4-函数重载"><a href="#8-4-函数重载" class="headerlink" title="8.4 函数重载"></a>8.4 函数重载</h2><p>编译器在检查函数特征标时，将把类型引用和类型本身视为同一个特征标。</p>
<p>匹配函数时，并不区分const和非const变量。</p>
<h2 id="8-5函数模板"><a href="#8-5函数模板" class="headerlink" title="8.5函数模板"></a>8.5函数模板</h2><p>最初，编译器只能通过隐式实例化，来使用模板生成函数定义，但现在C++还允许显式实例化(explicit instantiation)。这意味着可以直接命令编译器创建特定的实例，如Swap<int>()。其语法是，声明所需的种<br>类一用◇符号指示类型，并在声明前加上关键字template:</int></p>
<p>template void Swap<int>(int, int); &#x2F;&#x2F; explicit instantiation</int></p>
<p>有一个相关的问题是decltype本身无法解决的。请看下面这个不完整的模板函数：</p>
<p><img src="/2023/10/08/C++PrimerPlus/image-20231008164603225.png" alt="image-20231008164603225"></p>
<p>同样，无法预先知道将x和y相加得到的类型。好像可以将返回类型设置为decltype(x+y),但不幸的是，此时还未声明参数x和y,它们不在作用域内（编译器看不到它们，也无法使用它们）。必须在声明参数后使用decltype。为此，C++新增了一种声明和定义函数的语法。下面使用内置类型来说明这种语法的工作原理。对于下面的原型：</p>
<p><img src="/2023/10/08/C++PrimerPlus/image-20231008164728636.png" alt="image-20231008164728636"></p>
<h2 id="8-7-复习题"><a href="#8-7-复习题" class="headerlink" title="8.7 复习题"></a>8.7 复习题</h2><p>1．哪种函数适合定义为内联函数?</p>
<p>只有一行代码的小型、非递归函数适合作为内联函数。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/07/ComputerNetwork/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="枫叶">
      <meta itemprop="description" content="今天科研了吗">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶苑">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/07/ComputerNetwork/" class="post-title-link" itemprop="url">Computer Networks</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-10-07 19:51:25" itemprop="dateCreated datePublished" datetime="2023-10-07T19:51:25+08:00">2023-10-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-09 21:31:27" itemprop="dateModified" datetime="2023-10-09T21:31:27+08:00">2023-10-09</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="第二章-传输层"><a href="#第二章-传输层" class="headerlink" title="第二章 传输层"></a>第二章 传输层</h1><p>网络应用是计算机网络存在的理由。</p>
<h2 id="2-1-应用层协议原理"><a href="#2-1-应用层协议原理" class="headerlink" title="2.1 应用层协议原理"></a>2.1 应用层协议原理</h2><p>应用程序体系结构：客户-服务器体系结构和对等（P2P）体系结构、混合体结构。</p>
<h3 id="C-S结构"><a href="#C-S结构" class="headerlink" title="C&#x2F;S结构"></a>C&#x2F;S结构</h3><p>服务器：服务于 来自许多其他成为客户的主机的请求。</p>
<p>客户之间不直接通信。</p>
<p>服务器有固定的IP地址。</p>
<p>eg：Web、FTP、Telnet和电子邮件</p>
<p>扩展性差</p>
<h3 id="P2P结构"><a href="#P2P结构" class="headerlink" title="P2P结构"></a>P2P结构</h3><p>应用程序在间断连接的主机对之间使用直接通信，成为对等方。</p>
<p>eg：文件共享（BitTorrent）、迅雷、因特网电话(Skype)，IPTV </p>
<p>自扩展性好。</p>
<p>三个挑战：</p>
<ul>
<li>ISP友好</li>
<li>安全性</li>
<li>激励</li>
</ul>
<h3 id="混合体"><a href="#混合体" class="headerlink" title="混合体"></a>混合体</h3><p>Napster</p>
<ul>
<li>文件搜索：集中</li>
<li>文件传输：P2P</li>
</ul>
<p>即时通信</p>
<p><strong>进程</strong>：进行通信</p>
<p>在两个不同端系统上的进程，通过跨越计算机网络交换报文相互通信。</p>
<p>对于p2p，下载文件的等待方标识为客户，上载方为服务器</p>
<p>在给定的一对进程之间的通信会话场景中，发起通信的进程为客户，在会话开始时等待联系的是服务器。</p>
<p><strong>套接字</strong>：进程通过套接字（软件接口）向网络发送报文和从网络接收报文。</p>
<p>主机由IP地址标识，目的地端口号指定运行在接受主机上的接收进程。</p>
<p>Web服务器80号端口，邮件服务器进程(使用SMTP协议)25号端口</p>
<p>应用程序服务要求：</p>
<ul>
<li>可靠数据传输</li>
<li>吞吐量 带宽敏感的应用</li>
<li>定时</li>
<li>安全性</li>
</ul>
<h3 id="TCP服务"><a href="#TCP服务" class="headerlink" title="TCP服务"></a>TCP服务</h3><p>运输层协议</p>
<p>包括面向连接和可靠数据传输服务</p>
<p>无加密机制，SSL安全套接字层（在应用层）</p>
<p>拥塞控制</p>
<p>流量控制</p>
<h3 id="UDP服务"><a href="#UDP服务" class="headerlink" title="UDP服务"></a>UDP服务</h3><p>运输层协议</p>
<p>不提供不必要服务的轻量级运输协议，仅提供最小服务，是无连接的，因此在两个进程通信前没有握手过程。不可靠数据传送服务。</p>
<p>无拥塞控制</p>
<p>套接字是2元组的一个具有本地意义的标识，IP， port(源端指定)</p>
<p>没有拥塞控制和流量控制，应用能够按照设定的速度发送数据</p>
<p>而在TCP上面的应用，应用发送数据的速度和主机向网络发送的实际速度是不一致的，因为有流量控制和拥塞控制。</p>
<p>均不提供任何定时或者带宽保证</p>
<p><img src="/2023/10/07/ComputerNetwork/image-20231007204153804.png" alt="image-20231007204153804"></p>
<h3 id="应用层协议"><a href="#应用层协议" class="headerlink" title="应用层协议"></a>应用层协议</h3><p>定义了交换的报文类型，如请求和响应</p>
<p>各种报文类型的语法，</p>
<p>字段的语义</p>
<p>一个进程何时以及如何发送报文，对报文进行相应的规则。</p>
<p>是网络应用的一部分</p>
<h2 id="2-2-Web和Http"><a href="#2-2-Web和Http" class="headerlink" title="2.2  Web和Http"></a>2.2  Web和Http</h2><p>Web页：由一些对象组成</p>
<p>对象可以是HTML文件、JPEG图像、Java小程序、声音剪辑文件等</p>
<p>Web页含有一个基本的HTML文件，该基本HTML文件又包含若干对象的引用（链接）</p>
<p>通过URL对每个对象进行引用</p>
<p>访问协议，用户名，口令字，端口等；</p>
<p>URL格式:</p>
<p><img src="/2023/10/07/ComputerNetwork/image-20231007205501234.png" alt="image-20231007205501234"></p>
<h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><p>Web的应用层协议超文本传输协议，是Web的核心</p>
<p>HTTP使用TCP作为它的支撑运输协议</p>
<ul>
<li><p>客户发起一个与服务器的TCP连接(建立套接字) ，端口号为80</p>
</li>
<li><p>服务器接受客户的TCP连接</p>
</li>
<li><p>在浏览器(HTTP客户端)与Web服务器(HTTP服务器server)交换HTTP报文(应用层协议报文)</p>
</li>
<li><p>TCP连接关闭</p>
</li>
</ul>
<p>HTTP是无状态的 服务器并不维护关于客户的任何信息</p>
<p>维护状态的协议很复杂！</p>
<ul>
<li><p>必须维护历史信息(状态)</p>
</li>
<li><p>如果服务器&#x2F;客户端死机，它们的状态信息可能不一致，二者的信息必须是一致</p>
</li>
<li><p>无状态的服务器能够支持更多的客户端</p>
</li>
</ul>
<p>HTTP连接</p>
<ul>
<li>非持久HTTP<ul>
<li>最多只有一个对象在TCP连接上发送</li>
<li>下载多个对象需要多个TCP连接</li>
<li>HTTP&#x2F;1.0使用非持久连接</li>
</ul>
</li>
<li>持久HTTP<ul>
<li>多个对象可以在一个（在客户端和服务器之间的）TCP连接上传输</li>
<li>HTTP&#x2F;1.1 默认使用持久连接</li>
</ul>
</li>
</ul>
<p>非持久HTTP</p>
<p>1a.HTTP客户端在端口号80发起一个到服务器<a target="_blank" rel="noopener" href="http://www.someschool.edu的连接/">www.someSchool.edu的连接</a></p>
<p>1b. 位于主机<a target="_blank" rel="noopener" href="http://www.someschool.edu的http服务器在80号端口等待连接,接受连接并通知客户端/">www.someSchool.edu的HTTP服务器在80号端口等待连接，接受连接并通知客户端</a></p>
<p>2.HTTP客户端向TCP连接的套接字发送HTTP请求报文，报文表示客户端需要对象someDepartment&#x2F;home.index</p>
<p>3.HTTP服务器接收到请求报文，检索出被请求的对象，将对象封装在一个响应报文，并通过其套接字象客户端发送</p>
<p>4.HTTP关闭TCP连接。</p>
<p>5.HTTP客户端收到包含html文件的响应报文，并显示html。然后对html文件进行检查，找到10引用对象</p>
<p>6.对10jpeg对象，重复1-5步</p>
<h3 id="响应时间模型"><a href="#响应时间模型" class="headerlink" title="响应时间模型"></a>响应时间模型</h3><p>往返时间RTT（round-triptime）：一个小的分组从客户端到服务器，在回到客户端的时间（传输时间忽略）</p>
<p>响应时间：</p>
<ul>
<li><p>一个RTT用来发起TCP连接</p>
</li>
<li><p>一个RTT用来HTTP请求并等待HTTP响应</p>
</li>
<li><p>文件传输时间</p>
</li>
</ul>
<p>共：2RTT+传输时间</p>
<h3 id="持久HTTP"><a href="#持久HTTP" class="headerlink" title="持久HTTP"></a>持久HTTP</h3><p>非持久HTTP的缺点：</p>
<ul>
<li>每个对象要2个RTT</li>
<li>操作系统必须为每个TCP连接分配资源</li>
<li>但浏览器通常打开并行TCP连接，以获取引用对象</li>
</ul>
<p>持久HTTP</p>
<ul>
<li>服务器在发送响应后，仍保持TCP连接</li>
<li>在相同客户端和服务器之间的后续请求和响应报文通过相同的连接进行传送</li>
<li>客户端在遇到一个引用对象的时候，就可以尽快发送该对象的请求</li>
</ul>
<p>非流水方式的持久HTTP：</p>
<ul>
<li>客户端只能在收到前一个响应后才能发出新的请求</li>
<li>每个引用对象花费一个RTT</li>
</ul>
<p>流水方式的持久HTTP：</p>
<ul>
<li>HTTP&#x2F;1.1的默认模式</li>
<li>客户端遇到一个引用对象就立即产生一个请求</li>
<li>所有引用（小）对象只花费一个RTT是可能的</li>
</ul>
<h3 id="http报文格式"><a href="#http报文格式" class="headerlink" title="http报文格式"></a>http报文格式</h3><h4 id="HTTP请求报文"><a href="#HTTP请求报文" class="headerlink" title="HTTP请求报文"></a>HTTP请求报文</h4><p>用ASCII文本写</p>
<p>每行由一个回车和换行符结束，最后一行再附加一个回车换行符</p>
<p>第一行为请求行，后继的首部行</p>
<p>请求行：方法字段、URL字段、HTTP版本字段</p>
<p>首部行：</p>
<p>Host: 指明了对象所在的主机</p>
<p>User-agent:指明用户代理，即向服务器发送请求的浏览器的类型</p>
<p>Connection：close首部行，要求服务器在发送完被请求的对象后就关闭这条连接</p>
<p>accept-language:fr 表示用户想得到该对象的法语版本</p>
<p>使用POST，实体体中包含的是用户在表单字段中的输入值</p>
<p>URL方式：</p>
<ul>
<li>方法：GET</li>
<li>输入通过请求行的URL字段上载</li>
</ul>
<p><img src="/2023/10/07/ComputerNetwork/image-20231008085512906.png" alt="image-20231008085512906"></p>
<p><img src="/2023/10/07/ComputerNetwork/image-20231008085558184.png" alt="image-20231008085558184"></p>
<h4 id="方法类型"><a href="#方法类型" class="headerlink" title="方法类型"></a>方法类型</h4><p>HTTP&#x2F;1.0</p>
<ul>
<li>GET</li>
<li>POST</li>
<li>HEAD<ul>
<li>要求服务器在响应报文中不包含请求对象→故障跟踪</li>
</ul>
</li>
</ul>
<p>HTTP&#x2F;1.1</p>
<ul>
<li>GET, POST, HEAD</li>
<li>PUT<ul>
<li>将实体主体中的文件上载<br>到URL字段规定的路径</li>
</ul>
</li>
<li>DELETE<ul>
<li>删除URL字段规定的文件</li>
</ul>
</li>
</ul>
<h4 id="HTTP响应报文"><a href="#HTTP响应报文" class="headerlink" title="HTTP响应报文"></a>HTTP响应报文</h4><p><img src="/2023/10/07/ComputerNetwork/image-20231008091022857.png" alt="image-20231008091022857"></p>
<p>初始状态行：协议版本字段、状态码、相应状态信息</p>
<p>首部行：服务器用Connection: close首部行告诉客户，发送完报文后将关闭该TCP连接。</p>
<p>Date:首部行指示服务器产生并发送该响应报文的日期和时间。值得一提的是，这个时间不是指对象创建或者最后修改的时间;而是服务器从它的文件系统中检索到该对象,插入到响应报文,并发送该响应报文的时间。</p>
<p>Server:首部行指示该报文是由一台Apache Web服务器产生的，它类似于HTTP请求报文中的 User- agent:首部行。</p>
<p>Last-Modified:首部行指示了对象创建或者最后修改的日期和时间。Last-Modified:首部行对既可能在本地客户也可能在网络缓存服务器上的对象缓存来说非常重要。我们将很快详细地讨论缓存服务器（也叫代理服务器)。</p>
<p>Content-Length:首部行指示了被发送对象中的字节数。</p>
<p>Content-Type:首部行指示了实体体中的对象是HTML文本。(该对象类型应该正式地由 Content-Type:首部行而不是用文件扩展名来指示。)</p>
<h4 id="HTTP响应状态码"><a href="#HTTP响应状态码" class="headerlink" title="HTTP响应状态码"></a>HTTP响应状态码</h4><p>位于服务器→客户端的响应报文中的首行</p>
<p>一些状态码的例子:</p>
<p>200 OK</p>
<ul>
<li>请求成功，请求对象包含在响应报文的后续部分</li>
</ul>
<p>301 Moved Permanently</p>
<ul>
<li>请求的对象已经被永久转移了;新的URL在响应报文的Location:首部行中指定</li>
<li>客户端软件自动用新的URL去获取对象</li>
</ul>
<p>400 Bad Request</p>
<ul>
<li>一个通用的差错代码，表示该请求不能被服务器解读</li>
</ul>
<p>404Not Found</p>
<ul>
<li>请求的文档在该服务上没有找到</li>
</ul>
<p>505 HTTP version Not supported</p>
<h4 id="用户-服务器状态：cookies"><a href="#用户-服务器状态：cookies" class="headerlink" title="用户-服务器状态：cookies"></a>用户-服务器状态：cookies</h4><p>大多数主要的门户网站使用cookies</p>
<p>4个组成部分:</p>
<p>1)在HTTP响应报文中有一个cookie的首部行</p>
<p>2)在HTTP请求报文含有一个cookie的首部行</p>
<p>3)在用户端系统中保留有一个cookie文件，由用户的浏览器管理</p>
<p>4)在Web站点有一个后端数据库</p>
<p>Cookies能带来什么:</p>
<ul>
<li>用户验证</li>
<li>购物车</li>
<li>推荐</li>
<li>用户状态(Web e-mail)</li>
</ul>
<p>Cookies与隐私：</p>
<ul>
<li>Cookies允许站点知道许多关于用户的信息</li>
<li>可能将它知道的东西卖给第三方</li>
<li>使用重定向和cookie的搜索引擎还能知道用户更多的信息<ul>
<li>如通过某个用户在大量站点上的行为，了解其个人浏览方式的大致模式</li>
</ul>
</li>
<li>广告公司从站点获得信息</li>
</ul>
<p>如何维持状态：</p>
<ul>
<li>协议端节点:在多个事务上，发送端和接收端维持状态</li>
<li>cookies: http报文携带状态信息</li>
</ul>
<p>Web缓存(代理服务器)</p>
<p>目标：不访问原始服务器，就满足客户的请求</p>
<ul>
<li>用户设置浏览器:通过缓存访问Web</li>
<li>浏览器将所有的HTTP请求发给缓存<ul>
<li>在缓存中的对象:缓存直接返回对象</li>
<li>如对象不在缓存，缓存请求原始服务器，然后再将对象返回给客户端</li>
</ul>
</li>
</ul>
<p>缓存既是客户端又是服务器</p>
<p>通常缓存是由ISP安装(大学、公司、居民区ISP)</p>
<p>为什么要使用Web缓存?</p>
<ul>
<li>降低客户端的请求响应时间</li>
<li>可以大大减少一个机构内部网络与Internent接入链路上的流量</li>
<li>互联网大量采用了缓存:可以使较弱的ICP(网络内容服务商)也能够有效提供内容</li>
</ul>
<p>通过使用内容分发网络(Content Distri-bution Network,CDN),Web缓存器正在因特网中发挥着越来越重要的作用。CDN公司在因特网上安装了许多地理上分散的缓存器，因而使大量流量实现了本地化。有多个共享的CDN(例如Akamai和Lime-1ight)和专用的CDN(例如谷歌和微软)。</p>
<p>条件GET方法</p>
<p>尽管高速缓存能减少用户感受到的响应时间，但也引人了一个新的问题，即存放在缓存器中的对象副本可能是陈旧的。</p>
<ul>
<li>目标：如果缓存器中的对象拷贝是最新的，就不要发送对象</li>
<li>缓存器: 在HTTP请求中指定缓存拷贝的日期If-modified-since:<date></date></li>
<li>服务器: 如果缓存拷贝陈旧，则响应报文没包含对象:HTTP&#x2F;1.0 304 Not Modified</li>
</ul>
<h2 id="2-3-FTP"><a href="#2-3-FTP" class="headerlink" title="2.3 FTP"></a>2.3 FTP</h2><p>向远程主机上传输文件或从远程主机接收文件，运行在</p>
<p>客户&#x2F;服务器模式</p>
<p>客户端:发起传输的一方</p>
<p>服务器:远程主机</p>
<p>ftp:RFC 959</p>
<p>ftp服务器:端口号为21</p>
<ul>
<li><p>FTP客户端与FTP服务器通过端口21联系，并使用TCP为传输协议</p>
</li>
<li><p>客户端通过控制连接获得身份确认</p>
</li>
<li><p>客户端通过控制连接发送命令浏览远程目录</p>
</li>
<li><p>收到一个文件传输命令时，服务器打开一个到客户端的数据连接</p>
</li>
<li><p>一个文件传输完成后，服务器关闭连接</p>
</li>
<li><p>服务器打开第二个TCP数据连接用来传输另一个文件</p>
</li>
<li><p>控制连接:带外（“out of band”）传送</p>
</li>
</ul>
<p>FTP服务器维护用户的状态信息:当前路径、用户帐户与控制连接对应</p>
<p>有状态</p>
<p>命令样例：</p>
<ul>
<li>在控制连接上以ASCII文本方式传送</li>
<li>USER usernamePAss password</li>
<li>LIST:请服务器返回远程主机当前目录的文件列表</li>
<li>RETR filename:从远程主机的当前目录检索文件(gets)</li>
<li>STOR filename:向远程主机的当前目录存放文件(puts)</li>
</ul>
<p>返回码样例：</p>
<ul>
<li>状态码和状态信息(同HTTP)331 Username OK, password required</li>
<li>125 data connectionalready open ; transfer starting</li>
<li>425 Can’ t open dataconnection</li>
<li>452 Error writingfile</li>
</ul>
<h2 id="2-4-Email"><a href="#2-4-Email" class="headerlink" title="2.4 Email"></a>2.4 Email</h2><p>3个主要组成部分：</p>
<ul>
<li>用户代理</li>
<li>邮件服务器</li>
<li>简单邮件传输协议:SMTP</li>
</ul>
<p>用户代理</p>
<ul>
<li>又名“邮件阅读婴”</li>
<li>撰写、编辑和阅读邮件</li>
<li>如Outlook、Foxmail</li>
<li>输出和输入邮件保存在服务器上</li>
</ul>
<p>邮件服务器</p>
<ul>
<li>邮箱中管理和维护发送给用户的邮件</li>
<li>输出报文队列保持待发送邮件报文</li>
<li>邮件服务器之间的SMTP协议:发送email报文<ul>
<li>客户:发送方邮件服务器</li>
<li>服务器:接收端邮件服务器</li>
</ul>
</li>
</ul>
<p>SMTP</p>
<ul>
<li>使用TCP在客户端和服务器之间传送报文，端口号为25</li>
<li>直接传输:从发送方服务器到接收方服务器</li>
<li>传输的3个阶段<ul>
<li>握手</li>
<li>传输报文</li>
<li>关闭</li>
</ul>
</li>
<li>命令&#x2F;响应交互<ul>
<li>命令:ASCII文本</li>
<li>响应:状态码和状态信息</li>
</ul>
</li>
<li>报文必须为7位ASCII码</li>
</ul>
<p>客户发送了5条命令:</p>
<ul>
<li>HELO(是HELLO的缩写)、MAIL FROM、RCPT TO、DATA 以及 QUIT。这些命令都是自解释的。</li>
<li>该客户通过发送一个只包含一个句点的行，向服务器指示该报文结束了。(按照ASCII码的表示方法，每个报文以 CRLF.CRLF结束，其中的CR和LF分别表示回车和换行。)</li>
</ul>
<p>总结</p>
<ul>
<li>SMTP使用持久连接</li>
<li>SMTP要求报文（(首部和主体）为7位ASCII编码</li>
<li>SMTP服务器使用 <ul>
<li>CRLF.CRLF决定报文的尾部</li>
</ul>
</li>
</ul>
<p>HTTP比较</p>
<ul>
<li>HTTP:拉(pull)</li>
<li>SMTP:推(push)</li>
<li>二者都是ASCTI形式的命令&#x2F;响应交互、状态码</li>
<li>HTTP:每个对象封装在各自的响应报文中</li>
<li>SMTP:多个对象包含在一个报文中</li>
</ul>
<h3 id="邮件报文格式"><a href="#邮件报文格式" class="headerlink" title="邮件报文格式"></a>邮件报文格式</h3><p>SMTP:交换email报文的协议</p>
<p>RFC 822:文本报文的标准:</p>
<ul>
<li><p>首部行：如：</p>
<ul>
<li><p>To:</p>
</li>
<li><p>From:</p>
</li>
<li><p>Subject:</p>
<p>与SMTP命令不同</p>
</li>
</ul>
</li>
<li><p>主体：</p>
<ul>
<li>报文，只能是ASCII码字符</li>
</ul>
</li>
</ul>
<p>报文格式：多媒体扩展</p>
<ul>
<li>MIME:多媒体邮件扩展(multimedia mail extension)RFC 2045,2056</li>
<li>在报文首部用额外的行申明MIME内容类型</li>
</ul>
<p><img src="/2023/10/07/ComputerNetwork/image-20231008151830276.png" alt="image-20231008151830276"></p>
<h3 id="邮件访问协议"><a href="#邮件访问协议" class="headerlink" title="邮件访问协议"></a>邮件访问协议</h3><p>SMTP:传送到接收方的邮件服务器</p>
<p>邮件访问协议:从服务器访问邮件</p>
<ul>
<li>POP:邮局访问协议(Post Office Protocol&gt;[RFC 1939]<ul>
<li>用户身份确认(代理&lt;–&gt;服务器)并下载</li>
</ul>
</li>
<li>IMAP: Internet邮件访问协议( Internet Mail AccessProtocol[RFC 1730]<ul>
<li>更多特性(更复杂)</li>
<li>在服务器上处理存储的报文</li>
</ul>
</li>
<li>HTTP: Hotmail , yahoo! Mail等<ul>
<li>方便</li>
</ul>
</li>
</ul>
<p><img src="/2023/10/07/ComputerNetwork/Blog\source_posts\ComputerNetwork\image-20231009202619364.png" alt="image-20231009202619364"></p>
<h4 id="POP3协议"><a href="#POP3协议" class="headerlink" title="POP3协议"></a>POP3协议</h4><p>用户确认阶段</p>
<ul>
<li><p>客户端命令：</p>
<ul>
<li>user:申明用户名</li>
<li>pass : 口令</li>
</ul>
</li>
<li><p>服务器响应</p>
<ul>
<li>+OK</li>
<li>-ERR</li>
</ul>
</li>
</ul>
<p>事务处理阶段</p>
<ul>
<li>list:报文号列表</li>
<li>retr:根据报文号检索报文</li>
<li>dele:删除</li>
<li>quit</li>
</ul>
<p>先前的例子使用“下载并删除”模式。</p>
<ul>
<li>如果改变客户机，Bob不能阅读邮件</li>
<li>“下载并保留”:不同客户机上为报文的拷贝</li>
<li>POP3在会话中是无状态的</li>
</ul>
<p>本地管理文件夹</p>
<h4 id="IMAP"><a href="#IMAP" class="headerlink" title="IMAP"></a>IMAP</h4><ul>
<li>IMAP服务器将每个报文与一个文件夹联系起来</li>
<li>允许用户用目录来组织报文</li>
<li>允许用户读取报文组件</li>
<li>IMAP在会话过程中保留用户状态:<ul>
<li>目录名、报文ID与目录名之间映射</li>
</ul>
</li>
</ul>
<p>远程管理文件夹</p>
<h2 id="2-5-DNS"><a href="#2-5-DNS" class="headerlink" title="2.5 DNS"></a>2.5 DNS</h2><p>Domain Name System</p>
<h3 id="Dns的必要性"><a href="#Dns的必要性" class="headerlink" title="Dns的必要性"></a>Dns的必要性</h3><ul>
<li>IP地址标识主机、路由器</li>
<li>但IP地址不好记忆，不便人类使用(没有意义)</li>
<li>人类一般倾向于使用一些有意义的字符串来标识Internet上的设备<ul>
<li>例如: <a href="mailto:&#x71;&#122;&#104;&#x65;&#110;&#103;&#x40;&#117;&#x73;&#116;&#x63;&#46;&#x65;&#100;&#117;&#x2e;&#99;&#110;">&#x71;&#122;&#104;&#x65;&#110;&#103;&#x40;&#117;&#x73;&#116;&#x63;&#46;&#x65;&#100;&#117;&#x2e;&#99;&#110;</a>所在的邮件服务器</li>
<li><a target="_blank" rel="noopener" href="http://www.ustc.edu.cn所在的web服务器/">www.ustc.edu.cn所在的web服务器</a></li>
</ul>
</li>
<li>存在着“字符串”—IP地址的转换的必要性</li>
<li>人类用户提供要访问机器的“字符串”名称</li>
<li>由DNS负责转换成为二进制的网络地址</li>
</ul>
<h3 id="DNS系统需要解决的问题"><a href="#DNS系统需要解决的问题" class="headerlink" title="DNS系统需要解决的问题"></a>DNS系统需要解决的问题</h3><p>问题1:如何命名设备</p>
<ul>
<li>用有意义的字符串:好记，便于人类用使用</li>
<li>解决一个平面命名的重名问题:层次化命名</li>
</ul>
<p>问题2:如何完成名字到IP地址的转换</p>
<ul>
<li>分布式的数据库维护和响应名字查询</li>
</ul>
<p>问题3:如何维护:增加或者删除一个域，需要在域名系统中做哪些工作</p>
<p>DNS(Domain Name System)的历史</p>
<p>ARPANET的名字解析解决方案</p>
<ul>
<li>主机名:没有层次的一个字符串（一个平面&gt;</li>
<li>存在着一个（集中）维护站:维护着一张主机名-TP地址的映射文件: Hosts.txt</li>
<li>每台主机定时从维护站取文件</li>
</ul>
<p>ARPANET解决方案的问题</p>
<ul>
<li>当网络中主机数量很大时<ul>
<li>没有层次的主机名称很难分配</li>
<li>文件的管理、发布、查找都很麻烦</li>
</ul>
</li>
</ul>
<p>DNS总体思路和目标</p>
<ul>
<li>DNS的主要思路<ul>
<li>分层的、基于域的命名机制</li>
<li>若干分布式的数据库完成名字到IP地址的转换</li>
<li>运行在UDP之上端口号为53的应用服务</li>
<li>核心的Internet功能，但以应用层协议实现<ul>
<li>在网络边缘处理复杂性</li>
</ul>
</li>
</ul>
</li>
<li>DNS主要目的:</li>
<li>实现主机名-IP地址的转换(name&#x2F;IP translate)</li>
<li>其它目的<ul>
<li>主机别名到规范名字的转换: Host aliasing</li>
<li>邮件服务器别名到邮件服务器的正规名字的转换:Mail serveraliasing</li>
<li>负载均衡: Load Distribution</li>
</ul>
</li>
</ul>
<p>问题1:DNS名字空间(The DNS Name Space)</p>
<p>DNS域名结构</p>
<ul>
<li>一个层面命名设备会有很多重名</li>
<li>DNS采用层次树状结构的命名方法<br>o Internet根被划为几百个顶级域(top lever domains)<br>o通用的(generic)<br>.com; .edu ; .gov ; .int ; .mil ; .net ; .org.firm ; .hsop ; .web ; .arts ; .rec ;国家的(countries)<br>.cn ; .us ; .nl ; .jp<br>o每个(子)域下面可划分为若干子域(subdomains)o树叶是主机</li>
</ul>
<h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="枫叶"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">枫叶</p>
  <div class="site-description" itemprop="description">今天科研了吗</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2023-10 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">枫叶</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>


  















  

  

</body>
</html>
